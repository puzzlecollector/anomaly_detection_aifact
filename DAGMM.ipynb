{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02507b3f-66d0-47f0-8494-6070b24b1107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn import svm  \n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5166c5c6-06a9-472e-80f6-49984562632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\") \n",
    "test = pd.read_csv(\"test_data.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c860d57-b149-4f0b-80e1-f9e99fa5f589",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns={\"type\"}, inplace=True) \n",
    "test.drop(columns={\"type\"}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5fddb0-3f90-4fcc-9c00-14d36ce34184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, z_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "\n",
    "class Estimation(nn.Module):\n",
    "    def __init__(self, z_dim, hidden_dim, output_dim):\n",
    "        super(Estimation, self).__init__()\n",
    "        self.estimation = nn.Sequential(\n",
    "            nn.Linear(z_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.estimation(x)\n",
    "\n",
    "\n",
    "class DAGMM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim, n_gmm):\n",
    "        super(DAGMM, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, z_dim)\n",
    "        self.decoder = Decoder(z_dim, hidden_dim, input_dim)\n",
    "        self.estimation = Estimation(z_dim, hidden_dim, n_gmm)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z_c = self.encoder(x)\n",
    "        x_hat = self.decoder(z_c)\n",
    "        gamma = self.estimation(z_c)\n",
    "        return x_hat, z_c, gamma\n",
    "\n",
    "\n",
    "def train_dagmm(model, dataset, batch_size, epochs, learning_rate, device):\n",
    "    model.to(device)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "    best_loss = 9999999999999\n",
    "    best_epoch = -1 \n",
    "    for epoch in tqdm(range(epochs), position=0, leave=True):\n",
    "        train_loss = 0 \n",
    "        for batch in dataloader:\n",
    "            x = batch[0].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_hat, z_c, gamma = model(x)\n",
    "            recon_loss = criterion(x_hat, x)\n",
    "            loss = recon_loss # Add any other losses, e.g., energy-based losses \n",
    "            train_loss += loss.item() \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        \n",
    "        # print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "        if train_loss < best_loss: \n",
    "            best_loss = train_loss \n",
    "            best_epoch = epoch \n",
    "            torch.save(model.state_dict(), \"best_dagmm.pt\") \n",
    "    print(f\"best loss: {best_loss} | best epoch: {best_epoch}\") \n",
    "\n",
    "# Example usage\n",
    "input_dim = 7\n",
    "hidden_dim = 3\n",
    "z_dim = 2\n",
    "n_gmm = 2\n",
    "batch_size = 32\n",
    "epochs = 2000\n",
    "learning_rate = 1e-3\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b868e878-e26b-4480-8474-6c4c148773fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_dataset' with your actual dataset\n",
    "dagmm = DAGMM(input_dim, hidden_dim, z_dim, n_gmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac736366-ee70-4335-931f-0f562fbb9d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "scaler.fit(train) \n",
    "train = scaler.transform(train) \n",
    "\n",
    "train = torch.tensor(train).float() \n",
    "train_data = TensorDataset(train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1959013-a8f9-4c2a-8ba3-756caefd49fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052e8babc83e49ad8b09f346771da869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best loss: 0.13425777381053194 | best epoch: 1989\n"
     ]
    }
   ],
   "source": [
    "train_dagmm(dagmm, train_data, batch_size, epochs, learning_rate, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf69f379-b6c8-4d7f-85f8-cdec5f4b1a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = scaler.transform(test) \n",
    "test = torch.tensor(test).float() \n",
    "test_data = TensorDataset(test) \n",
    "test_sampler = SequentialSampler(test_data) \n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "167da9e8-147b-49de-82f5-1f70acb3bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7277af46c324f6a9f83023e000725ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dagmm = DAGMM(input_dim, hidden_dim, z_dim, n_gmm)\n",
    "checkpoint = torch.load(\"best_dagmm.pt\") \n",
    "print(best_dagmm.load_state_dict(checkpoint)) \n",
    "best_dagmm.to(device)\n",
    "\n",
    "criterion = nn.MSELoss() \n",
    "\n",
    "best_dagmm.eval() \n",
    "\n",
    "test_mse_scores = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), position=0, leave=True): \n",
    "        x = batch[0].to(device)\n",
    "        x_hat, z_c, gamma = best_dagmm(x)\n",
    "        recon_loss = criterion(x_hat, x) \n",
    "        test_mse_scores.append(recon_loss.item()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87e143af-a32d-4e59-9217-f33e1628d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 10 \n",
    "\n",
    "def mad_score(points): \n",
    "    m = np.median(points) \n",
    "    ad = np.abs(points - m) \n",
    "    mad = np.median(ad) \n",
    "    return 0.6745 * ad / mad \n",
    "\n",
    "z_scores = mad_score(test_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df436689-9f83-4cda-afbb-c479a0e9da9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = z_scores > gamma \n",
    "outliers = outliers.astype(int) \n",
    "submission = pd.read_csv(\"answer_sample.csv\") \n",
    "submission[\"label\"] = outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55df5d43-ffff-4c01-a949-10752a3d2f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"dagmm__.csv\",index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f575d469-80b8-448b-9d66-786d6204c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "443"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0 \n",
    "\n",
    "for i in range(len(outliers)): \n",
    "    if outliers[i] == 1: \n",
    "        cnt += 1 \n",
    "        \n",
    "cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ff69875-2b0d-4fb1-a57f-78cabf0ea738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"autoencoders_3_5_.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94eea69a-ade8-4ee1-9f43-0ed8135f25c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "386"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for i in range(len(df[\"label\"].values)): \n",
    "    if df[\"label\"].values[i] == 1: \n",
    "        cnt += 1 \n",
    "        \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7d065a-aa2a-4c47-8429-0c801daf4b94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
