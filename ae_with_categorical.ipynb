{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d1b8b26c-0263-4aef-a504-bc95d3cfa956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer \n",
    "from sklearn.ensemble import IsolationForest \n",
    "from sklearn import svm  \n",
    "from sklearn.mixture import GaussianMixture \n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "836971e0-6c0a-4efa-9da2-e07a5b222ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\") \n",
    "test = pd.read_csv(\"test_data.csv\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "294a12b1-f0c5-4592-a024-ff0d5036e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataframe \n",
    "train = train.sample(frac=1, random_state=42).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "512566ae-59fa-455c-ab9c-dab2cc688a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_inflow</th>\n",
       "      <th>air_end_temp</th>\n",
       "      <th>out_pressure</th>\n",
       "      <th>motor_current</th>\n",
       "      <th>motor_rpm</th>\n",
       "      <th>motor_temp</th>\n",
       "      <th>motor_vibe</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.04</td>\n",
       "      <td>60.24</td>\n",
       "      <td>0.7</td>\n",
       "      <td>39.34</td>\n",
       "      <td>3219.0</td>\n",
       "      <td>75.77</td>\n",
       "      <td>3.79</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.15</td>\n",
       "      <td>61.63</td>\n",
       "      <td>0.7</td>\n",
       "      <td>40.70</td>\n",
       "      <td>3330.0</td>\n",
       "      <td>77.00</td>\n",
       "      <td>3.85</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.12</td>\n",
       "      <td>48.04</td>\n",
       "      <td>0.7</td>\n",
       "      <td>27.41</td>\n",
       "      <td>2243.0</td>\n",
       "      <td>64.92</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88</td>\n",
       "      <td>56.38</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.00</td>\n",
       "      <td>3150.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.53</td>\n",
       "      <td>53.49</td>\n",
       "      <td>0.7</td>\n",
       "      <td>32.74</td>\n",
       "      <td>2679.0</td>\n",
       "      <td>69.77</td>\n",
       "      <td>3.49</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_inflow  air_end_temp  out_pressure  motor_current  motor_rpm  \\\n",
       "0        3.04         60.24           0.7          39.34     3219.0   \n",
       "1        3.15         61.63           0.7          40.70     3330.0   \n",
       "2        2.12         48.04           0.7          27.41     2243.0   \n",
       "3        0.88         56.38           0.7          14.00     3150.0   \n",
       "4        2.53         53.49           0.7          32.74     2679.0   \n",
       "\n",
       "   motor_temp  motor_vibe  type  \n",
       "0       75.77        3.79     5  \n",
       "1       77.00        3.85     7  \n",
       "2       64.92        3.25     4  \n",
       "3       72.00        3.05     2  \n",
       "4       69.77        3.49     6  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b0e471f-bac2-4d2b-93e2-5fb480c061ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() \n",
    "\n",
    "X_continuous = train[[\"air_inflow\", \"air_end_temp\", \"out_pressure\", \"motor_current\", \"motor_rpm\", \"motor_temp\", \"motor_vibe\"]] \n",
    "X_categorical = train[\"type\"] \n",
    "\n",
    "X_continuous = scaler.fit_transform(X_continuous)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7083ce2-452c-4ced-a9b2-a67981559f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_categorical_onehot = [] \n",
    "\n",
    "num_classes = len(np.unique(X_categorical)) \n",
    "\n",
    "for i in range(len(X_categorical)): \n",
    "    arr = [0 for _ in range(8)] \n",
    "    arr[X_categorical[i]] = 1 \n",
    "    X_categorical_onehot.append(arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f02d68d-a7d5-4096-86c1-3b581cd89dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module): \n",
    "    def __init__(self, input_dim, n_categories, embedding_dim): \n",
    "        super(AutoEncoder, self).__init__() \n",
    "        self.input_dim = input_dim\n",
    "        self.n_categories = n_categories \n",
    "        self.embedding_dim = embedding_dim \n",
    "        self.embedding = nn.Embedding(n_categories, embedding_dim) \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.input_dim + self.embedding_dim, 10), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(10, 5)\n",
    "        ) \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(5, 10), \n",
    "            nn.ELU(), \n",
    "            nn.Linear(10, self.input_dim + self.embedding_dim)\n",
    "        ) \n",
    "    def forward(self, x_continuous, x_categorical): \n",
    "        x_embedded = self.embedding(x_categorical) \n",
    "        x_embedded = torch.mean(x_embedded, dim=1) \n",
    "        x = torch.cat([x_continuous, x_embedded], dim=1) \n",
    "        encoded = self.encoder(x) \n",
    "        decoded = self.decoder(encoded) \n",
    "        return x, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1f6a04df-bff6-464b-9bee-c03a1d8282a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2463, 8])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32 \n",
    "\n",
    "X_continuous = torch.tensor(X_continuous).float() \n",
    "X_categorical_onehot = torch.tensor(X_categorical_onehot, dtype=int) \n",
    "\n",
    "X_categorical_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2ab0246a-2b77-41f2-aa1f-121c76dda73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(X_continuous, X_categorical_onehot) \n",
    "train_sampler = RandomSampler(train_data) \n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=32)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "849a2e77-ac71-4a2c-a1b6-7dd4b9669b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2f1c63b9124c909a61f7817407635b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average train loss : 8.129753877693037e-05\n",
      "average train loss : 1.4757343416766327e-05\n",
      "average train loss : 3.5069344682136496e-06\n",
      "average train loss : 1.6267119408380555e-05\n",
      "average train loss : 1.0293354534951504e-05\n",
      "average train loss : 3.0102474338550505e-06\n",
      "average train loss : 5.468058240588213e-06\n",
      "average train loss : 1.1089075923183527e-05\n",
      "average train loss : 2.344090823392541e-06\n",
      "best loss : 0.0001380180854084756 | best epoch: 1989\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") \n",
    "model = AutoEncoder(input_dim=7, n_categories=8, embedding_dim=16) \n",
    "model = model.to(device) \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss() \n",
    "best_loss = 99999999999 \n",
    "best_epoch = -1 \n",
    "\n",
    "for epoch in tqdm(range(2000), position=0, leave=True, desc=\"Epochs\"):\n",
    "    train_loss = 0 \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_continuous, b_categorical = batch  \n",
    "        b_inputs, decoded = model(b_continuous, b_categorical)\n",
    "        loss = criterion(decoded, b_inputs) \n",
    "        train_loss += loss.item() \n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()  \n",
    "    if train_loss < best_loss: \n",
    "        best_loss = train_loss \n",
    "        best_epoch = epoch \n",
    "        torch.save(model.state_dict(), \"Best_AE_Categorical.pt\")  \n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_dataloader) \n",
    "    if epoch%200 == 0 and epoch > 0: \n",
    "        print(f\"average train loss : {avg_train_loss}\") \n",
    "\n",
    "print(f\"best loss : {best_loss} | best epoch: {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99fa8ae5-de2b-420d-b508-7cd4331c6786",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_continuous = test[[\"air_inflow\", \"air_end_temp\", \"out_pressure\", \"motor_current\", \"motor_rpm\", \"motor_temp\", \"motor_vibe\"]] \n",
    "X_test_categorical = test[\"type\"]\n",
    "\n",
    "X_test_continuous = scaler.transform(X_test_continuous)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19ad7126-4763-49b3-a6a5-b9fcb29f5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_categorical_onehot = [] \n",
    "\n",
    "for i in range(len(X_test_categorical)): \n",
    "    arr = [0 for _ in range(num_classes)] \n",
    "    arr[X_test_categorical[i]] = 1 \n",
    "    X_test_categorical_onehot.append(arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c85eb366-b160-477b-9285-5b60e8ea6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_161/1174001004.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_continuous = torch.tensor(X_test_continuous).float()\n",
      "/tmp/ipykernel_161/1174001004.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test_categorical_onehot = torch.tensor(X_test_categorical_onehot, dtype=int)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([7389, 7]), torch.Size([7389, 8]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 1 \n",
    "X_test_continuous = torch.tensor(X_test_continuous).float() \n",
    "X_test_categorical_onehot = torch.tensor(X_test_categorical_onehot, dtype=int) \n",
    "\n",
    "X_test_continuous.shape, X_test_categorical_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "92295685-53ee-4928-b35f-f07010bdc1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TensorDataset(X_test_continuous, X_test_categorical_onehot) \n",
    "test_sampler = SequentialSampler(test_data) \n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f456f7f5-0546-4f61-999a-12de0add0a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (embedding): Embedding(8, 16)\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=10, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Linear(in_features=10, out_features=23, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = AutoEncoder(input_dim=7, n_categories=8, embedding_dim=16) \n",
    "checkpoint = torch.load(\"Best_AE_Categorical.pt\") \n",
    "print(best_model.load_state_dict(checkpoint)) \n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f212cbe3-d008-4dca-abf3-58790bd31add",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61ec1e37839e418496dc0141087bac32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss() \n",
    "\n",
    "best_model.eval() \n",
    "\n",
    "test_mse_scores = [] \n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, batch in tqdm(enumerate(test_dataloader), position=0, leave=True): \n",
    "        batch = tuple(t.to(device) for t in batch) \n",
    "        b_continuous, b_categorical = batch  \n",
    "        b_inputs, decoded = model(b_continuous, b_categorical)\n",
    "        loss = criterion(decoded, b_inputs) \n",
    "        test_mse_scores.append(loss.item())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99ff1fa1-f7ab-47b3-a770-73a046283c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad_score(points): \n",
    "    m = np.median(points) \n",
    "    ad = np.abs(points - m) \n",
    "    mad = np.median(ad) \n",
    "    return 0.6745 * ad / mad \n",
    "\n",
    "z_scores = mad_score(test_mse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ed24231-2983-402e-a174-4e8495a66d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gamma:50.5, cnt:399\n",
      "gamma:51.5, cnt:393\n",
      "gamma:60.5, cnt:359\n",
      "gamma:70.5, cnt:350\n",
      "gamma:80.5, cnt:345\n",
      "gamma:90.5, cnt:344\n",
      "gamma:100.5, cnt:344\n",
      "gamma:110.5, cnt:343\n",
      "gamma:120.5, cnt:343\n",
      "gamma:130.5, cnt:343\n",
      "gamma:140.5, cnt:343\n",
      "gamma:150.5, cnt:343\n",
      "gamma:160.5, cnt:343\n",
      "gamma:170.5, cnt:343\n",
      "gamma:180.5, cnt:343\n",
      "gamma:190.5, cnt:343\n"
     ]
    }
   ],
   "source": [
    "gammas = [50.5, 51.5, 60.5, 70.5, 80.5, 90.5, 100.5, 110.5, 120.5, 130.5, 140.5, 150.5, 160.5, 170.5, 180.5, 190.5] \n",
    "\n",
    "for gamma in gammas: \n",
    "    outliers = z_scores > gamma \n",
    "    outliers = outliers.astype(int) \n",
    "    submission = pd.read_csv(\"answer_sample.csv\") \n",
    "    submission[\"label\"] = outliers\n",
    "    \n",
    "    cnt = 0 \n",
    "    for i in range(len(outliers)): \n",
    "        if outliers[i] == 1: \n",
    "            cnt += 1 \n",
    "\n",
    "    submission.to_csv(f\"AE_Categorical_{gamma}_cnt_{cnt}.csv\",index=False)  \n",
    "    \n",
    "    print(f\"gamma:{gamma}, cnt:{cnt}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e41a6da-f83f-4f8c-b0b7-3b6678aa3755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
